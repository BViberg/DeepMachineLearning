{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A general procedure for supervised learning in Keras\n",
    "\n",
    "For most of the supervised learning tasks, the procedure we follow is comprised of the following steps:\n",
    "\n",
    "### Step 1: Data exploration\n",
    "The first step is normally to load the data and try to understand its properties. A few things that are usually useful:\n",
    "1. Check data formats.\n",
    "2. Visual inspection of data.\n",
    "3. Investigate (get some type of understanding for) how hard the problem is. \n",
    "\n",
    "\n",
    "### Step 2: Data preprocessing\n",
    "1. Normalise (or scale) input data. \n",
    "2. Convert the data to a different type, or organize it differently for the optimization (e.g. Numpy arrays, subsets of the dataset, etc.)\n",
    "3. Encode input and output data on a suitable form. For instance, we often use one-hot encoding to represent string variables.\n",
    "4. Split data into training, validation and test sets.\n",
    "\n",
    "\n",
    "### Step 3: Training\n",
    "1. Build a tentative network architecture (could be the simplest one you think could work, or based in previous sucesses).\n",
    "2. Select optimizer, performance measures and a few more hyperparameters. \n",
    "3. Train the network. \n",
    "4. Analyze performance on the training and validation sets. Adjust design decisions accordingly.\n",
    "\n",
    "\n",
    "### Step 4: Assesment\n",
    "1. Use the network for predictions in the test set.\n",
    "2. Evaluate the final quality of the model. **Attention**: Once this is done, you shouldn't alter your model anymore, otherwise you need a new test set (if you want a good estimate of your model's generalization capacity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to apply most of these steps to the task of correctly classifying an Iris plant, given its morphologic features present in the IRIS dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1  Import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Analyzing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task, we'll use all of the data, not focus on only one of the species or a subset of the features. The `plot` method can help us obtain different types of visualizations of the data in the `DataFrame`. For instance, we can use it to plot histograms of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.plot(kind='hist', bins=30, alpha=0.7, figsize=[15,6]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is somewhat informative, but we could get an even better grasp of the data by first separating it into the different species (it seems likely that different species will have different feature distributions), and then plotting the histograms.\n",
    "\n",
    "However, if we let the `plot` method automatically create the histogram bins where it wants, each histogram might have different ranges, which would make it harder to compare them. Instead, we create the bins ourselves and pass that as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'species' column, so we get only the numeric values of the dataset\n",
    "features_dataset = dataset.drop('species', axis=1)\n",
    "\n",
    "# Find maximum and minimum values\n",
    "maxval = np.max(features_dataset.values)\n",
    "minval = np.min(features_dataset.values)\n",
    "\n",
    "# Create 30 linearly spaced numbers in this range\n",
    "my_bins = np.linspace(minval, maxval, 30)\n",
    "print(my_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the species\n",
    "species_names = dataset['species'].unique()\n",
    "print(species_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each species name, plot a histogram\n",
    "for name in species_names:\n",
    "    dataset[dataset[\"species\"]==name].plot(kind=\"hist\", bins=my_bins, alpha=0.7, figsize=[15,4], title=name);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms that different species do have substantial differences in the distributions of each feature, e.g. the Setosa species has shorter sepals than the others, etc. \n",
    "\n",
    "Another way to gain more insight about the data is using the method `pairplot`, from the seaborn python module. This shows scatter plots between all feature pairs (hence the time required to run it increases exponentially with the number of features!) and histograms for each feature, color-coded by the species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(dataset, hue='species');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also helpful to check if the dataset is balanced. We can do so like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in a dictionary with the number of ocurrences of each species\n",
    "n = {}\n",
    "for name in species_names:\n",
    "    extract_rule = dataset['species']==name\n",
    "    n[name] = len(dataset[extract_rule])\n",
    "    \n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that each species occurs exactly 50 times in the dataset, so it's perfectly balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to prepare the data for the training. The first thing we should do is define the input and the output arrays for our network. \n",
    "\n",
    "Defining the input is as simple as extracting only the numeric columns of the dataset (this can also be conveniently done using the `drop` method, as done before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numerical values\n",
    "x = dataset[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].values\n",
    "\n",
    "# Print first 10 rows\n",
    "print(x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we used the `values` attribute to create `x` as a numpy array. This is important, since Keras expects numpy arrays when training our model. Trying to use `DataFrame` objects with Keras unfortunately results in very non-informative error messages, so make sure to have this in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the output vector requires one more step, because of the way we'll train our network. Since the optimizer needs to be able to compare the predictions made by the neural network (i.e. a numeric vector), with the desired output vector in order to decide how to alter the weights, it's a good idea to encode the output vector in a numeric format. One way of doing this is using [one-hot encoding](https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science).\n",
    "\n",
    "One of the easiest ways of one-hot encoding a string column in pandas is to use the [`get_dummies`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) method on that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['species'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the species column and one-hot encode it\n",
    "y = pd.get_dummies(dataset['species']).values\n",
    "\n",
    "# Print first 5 rows\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, in order to assess how well our classifier generalizes to new, unseen data, we would like to withhold part of the dataset from the training process. This withheld part is usually called the test set. \n",
    "\n",
    "Scikit-learn provides an easy way to do so, with the `train_test_split` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method randomly chooses which examples will be withheld, and here we want the test set to be comprised of approximately 30% of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use `x_train` and `y_train` to train the network, and `x_test` and `y_test` to evaluate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the required classes from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a `Sequential` model, and add one layer of neurons to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(3, input_dim=4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This layer has 3 neurons, and each neuron has 4 inputs to it. The output from these 3 neurons will correspond to our prediction vector, so we use a softmax activation to make it possible to interpret this as a probability mass function. \n",
    "\n",
    "This way we can conveniently compare our prediction vector with the correct output vector for each example using the categorical cross-entropy loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: to make sure you clearly understand what we're doing here, draw the network on a piece of paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we did in the linear regression part of this computer session, we now compile the model (i.e. configure it's learning process).\n",
    "\n",
    "Here, instead of SGD, we use the Adam solver with a learning rate of $0.1$. As said before, we use the categorical cross-entropy loss for the optimization routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.1), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the new argument we're using here, `metrics`. This is because we want to compute the accuracy of our model at each time step. When we have a classification task with a balanced dataset, the accuracy metric can help us to rank different models and to estimate the models' predictive power.\n",
    "\n",
    "The accuracy is defined as:\n",
    "\n",
    "$ Acc = \\frac{\\# \\text{Samples correctly classified}}{\\# \\text{Samples}} $\n",
    "\n",
    "From the definition, we see that accuracy is always a value between 0 and 1. An accuracy of 0 means that every single prediction made by our model is wrong, and an accuracy of 1 the exact opposite. For real life tasks, we usually obtain an accuracy between 0 and 1, and we aim to make it as high as possible.\n",
    "\n",
    "(there are also [other metrics in Keras](https://keras.io/metrics/) that we can use to evaluate our classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: what if our dataset was imbalanced? Would it still be a good idea to use accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to train the model. The only difference of this command from the `fit` call we used in the linear regression problem is that we now specify a `validation_split` parameter, which tells Keras we want to withhold part of the provided dataset from the training process, but still want to compute the current loss and accuracy in it (this is useful for several reasons, e.g. assessing if we are overfitting the model, when to stop the optimization, rank hyper-parameter choice, etc.). \n",
    "\n",
    "This withheld part is usually referred to as the validation set. [Here](https://stats.stackexchange.com/questions/19048/what-is-the-difference-between-test-set-and-validation-set) you can find more info about the difference between the training, validation and test sets, and why we usually divide the data this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=20, validation_split=0.4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, the classes aren't so hard to separate in the feature-space, so it's common to obtain a very high accuracy in the training and the validation set (almost 100%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Assesment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we would like to be able to evaluate how well the model can predict the class of new, unseen samples. This was the reason for withholding part of our data from the training process, so that now we have fresh, unseen samples. \n",
    "\n",
    "The idea now is to use the trained model to predict the class of each new sample, given its features, and then compare the predicted label with the correct label for each sample.\n",
    "\n",
    "---\n",
    "\n",
    "To compare the labels, we can use different techniques. As we saw before, we can compute the accuracy, but this time on the test set samples. However, although this helps us to evaluate the model's performance, it provides an incomplete picture. For instance, it doesn't explain the types of missclassifications we are doing.\n",
    "\n",
    "So that we can gather more information about the quality of our classifier, we'll also compute the confusion matrix of its predictions. The confusion matrix is a table layout of the predictions of the classifier, in which each row represents the labels of the predicted class and each column the labels of the correct class.\n",
    "\n",
    "---\n",
    "\n",
    "To illustrate, imagine we train a classifier on samples that are either from the 'dog' class or the 'cat' class. After training, we show it 50 new samples. 30 of these new samples are cats, and 20 are dogs.\n",
    "\n",
    "For the new cats, our classifier correctly predicts 28 of them, but in 2 samples it thinks they are from the 'dog' class. Further, the classifier correctly predicts 15 of the new dogs, and in 5 samples it thinks they are actually from the 'cat' class. \n",
    "\n",
    "The resulting confusion matrix for this example would be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th colspan=\"2\" rowspan=\"2\"></th>\n",
    "      <th colspan=\"2\"><b>Predicted label</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Cat</td>\n",
    "    <td>Dog</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td rowspan=\"2\"><b>True label</b></td>\n",
    "    <td>Cat</td>\n",
    "    <td>28</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Dog</td>\n",
    "    <td>5</td>\n",
    "    <td>15</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the element $C_{ij}$ ($i$-th row, $j$-th column), corresponds to the number of predictions of class $i$, when the true known class was the $j$-th class. This is not universal: some sources define the confusion matrix as the transpose of the one shown here. However, `sklearn` defines confusion matrices like this, so we'll adhere to this definition.\n",
    "\n",
    "A handy way of computing accuracy and the confusion matrix, given the predictions and the true labels, it to use the function `accuracy_score` and `confusion_matrix` from the scikit-learn module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the first step is to compute our predictions in the test set. For this, we'll use the `predict` method from our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set options for pretty printing the numpy array\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct labels are stored in `y_test`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the prediction and the correct expected output for each sample is a 3 dimensional vector, which is an approximation of the probability mass function of the classes for that sample, given its features. \n",
    "\n",
    "We can instead convert this into a \"hard\", single-value prediction by choosing the index of the element with the highest probability, for each sample. \n",
    "\n",
    "This can be easily done with the `argmax` method from numpy. The `axis` keyword passed as an argument specifies in which dimension we would like to search for the maximum value (e.g. row-wise or column-wise), and the value of 1 means row-wise (the default is 0, column-wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_class = np.argmax(y_test, axis=1)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred_class[:5])\n",
    "print(y_test_class[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see here which of the first 5 elements were correctly classified. \n",
    "\n",
    "Now, to compute the accuracy, we use the `accuracy_score` function mentioned earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test_class, y_pred_class)\n",
    "print(\"Accuracy: %.2f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lastly, we can compute the confusion matrix using the `confusion_matrix` method from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_class, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: What can you conclude from this confusion matrix? Which classes are easy/hard to separate?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
