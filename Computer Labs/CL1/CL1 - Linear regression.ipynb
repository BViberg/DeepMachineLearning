{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this computer lab, we'll be using the IRIS dataset. Initially, we'll only look at a subset of it, and perform linear regression on two features of a given class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1  Import the necessary modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use these three different modules, and one of the functions from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last line is needed in order to show matplotlib plots in notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2  Read the dataset from a .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the [IRIS dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) using Pandas. The method `read_csv()` returns a `DataFrame` object containing the data found in the provided .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3  Analyze the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is comprised of morphologic data from three different species of the Iris flowers: Setosa, Virginica and Versicolor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th> <center>Iris Setosa</center> </th>\n",
    "    <th> <center>Iris Virginica</center> </th> \n",
    "    <th> <center>Iris Versicolor</center> </th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"https://upload.wikimedia.org/wikipedia/commons/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg\" alt=\"Iris Setosa\"></td>\n",
    "    <td><img src=\"https://upload.wikimedia.org/wikipedia/commons/9/9f/Iris_virginica.jpg\" alt=\"Iris Virginica\"></td>\n",
    "    <td><img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/Blue_Flag%2C_Ottawa.jpg\" alt=\"Iris Virginica\"></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lenght and width of both the petals and the sepals of each flower, together with its corresponding species were measured and stored in this dataset. Sepals and petals are both parts of a flower. Sepals are the outermost part of the whorl and the petals are the innermost part.\n",
    "![](http://terpconnect.umd.edu/~petersd/666/html/iris_with_labels.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what's inside the dataset now. The attribute `shape` of `DataFrame` objects returns the dimensions of the data inside it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this dataset has 150 rows and 5 columns. It's easy to infer that this means 150 flowers were collected, and 5 different features were registered for each one. But we can also take a closer look at them, using the method `head()`, which returns the first 5 rows by default (you can also pass a parameter to it, which specifies a different amount of rows to be shown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the header names for each column, together with the first rows, confirming that the species and morphologic measurements for each flower were collected. We can extract individual columns of this `DataFrame` by indexing using their names, for instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"sepal_length\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can check which species are present in the dataset using the `unique` method,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[\"species\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we see that only these three species are present in this dataset, as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also learn more about the data types of each column with the method `info`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the first four columns' elements are floating point numbers, and the last column's elements are objects (in this case, strings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4  Extract the desired data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this initial task, we are only interested in the setosa species. This corresponds to all the rows which have the column 'species' equal to the string 'setosa'. In order to extract these rows, we use [logical indexing in Pandas](https://pandas.pydata.org/pandas-docs/stable/indexing.html#boolean-indexing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This returns a boolean series, which we can then use to index our DataFrame object\n",
    "extract_rule = (dataset['species']=='setosa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the boolean series to index the DataFrame object\n",
    "setosa_dataset = dataset[extract_rule]\n",
    "setosa_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we want to investigate the relationship between two features of this species, the 'sepal_length' and 'sepal_width'. To extract these, we [index the `DataFrame` using the name of the columns](https://pandas.pydata.org/pandas-docs/stable/indexing.html#selection-by-label)  we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = setosa_dataset['sepal_length'].values\n",
    "y = setosa_dataset['sepal_width'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the attribute `values` in a `DataFrame` object returns a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use matplotlib to plot all the examples in a 2D plane, where each dimension is one of the features described earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x,y)\n",
    "ax.set_xlabel('sepal length')\n",
    "ax.set_ylabel('sepal width');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the relation between these features could be approximated using a linear function, such as \n",
    "$f(x) = w\\cdot x + b$. Let's try finding the parameters $w$ and $b$ that would make the best approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5  Guess the values of w and b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with some educated guesses. To make this more convenient, we'll first define a function to plot a scatter plot of the provided data, together with a straight line with parameters specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to plot the data and a parameterized line\n",
    "def plot_data_and_line(w, b, x, y, ax, line_color='r', line_label=''):\n",
    "    \n",
    "    # Create points lying on the line\n",
    "    xline = np.unique(x)\n",
    "    yline = w*xline + b\n",
    "\n",
    "    # Plot both the line and the points from the dataset\n",
    "    ax.scatter(x,y, color='C0')\n",
    "    ax.plot(xline, yline, color=line_color, label=line_label)\n",
    "    ax.set_xlabel('sepal length')\n",
    "    ax.set_ylabel('sepal width') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_data_and_line(1, -1, x, y, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, another way of evaluating the quality of our approximation is to compute the MSE (mean squared error) between the true y features in the dataset and our predictions. So that we can use this value as well to guide our guesses, create a function to compute it (first, it might be beneficial to write down the analytical expression for it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "84a068549164d7d4c62f18c3201a545b",
     "grade": true,
     "grade_id": "cell-17bd84c29b5dc802",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a function to compute the MSE\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try different values of $w$ and $b$ and see how the resulting linear approximation looks like, compared to the scatter plot of our data. Using both the plot and the MSE, try searching for values of $w$ and $b$ that yield a good approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "dc0d1c7d175ebd319359d29a0a453261",
     "grade": true,
     "grade_id": "cell-5df4a2b30a9d05e5",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Guess the values for w and b\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Plot your guess\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots()\n",
    "plot_data_and_line(w, b, x, y, ax);\n",
    "\n",
    "# Compute MSE of the guess\n",
    "y_guess = w*x+b\n",
    "print(\"MSE of your guess:\", MSE(y,y_guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Training a model for linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of trying to find the parameters that give the best approximation by trial and error, we'll use Keras' framework to build and optimize a linear regressor neural network. Actually, we'll be using Keras and Tensorflow.\n",
    "\n",
    "Tensorflow is what is called the 'backend' of Keras in this case, taking care of the matrix computations and parallelization necessary to speed up the code. Keras, on the other hand, is the Python package we'll use to interface with Tensorflow, using higher-level abstractions. That is, instead of thinking about the low-level details of tensors and the actual computations involved, we'll be thinking about neurons and network architectures, optimizers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1  Importing the necessary modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the necessary modules from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2  Create the Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of linear regression that we've been tackling so far can be seen as training a neural network consisting of only one neuron, with one weight and one bias. This model can be easily specified and trained in Keras, as we'll show ahead.\n",
    "\n",
    "In Keras, [models can be of two different types](https://keras.io/models/about-keras-models/#about-keras-models). For this task, it's enough to use the simpler one, the [`sequential`](https://keras.io/models/sequential/) model. The following code initializes such a model and then calls its `add` method in order to add the first (and only) layer. Finally, this calls the [`compile`](https://keras.io/models/sequential/#compile) method, in which we configure the learning process by specifying the loss and optimizer to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=1, kernel_initializer='zeros', bias_initializer='zeros'))\n",
    "model.compile(loss='mean_squared_error', optimizer='SGD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3  Optimize the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have specified the model and how we want to train it, calling the [`fit`](https://keras.io/models/sequential/#fit) method starts the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x,y,epochs=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the final MSE obtained (~0.066). Compare it to the one obtained using the guessed parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4  Extract optimal parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the `fit` method does show us the final obtained MSE, it does not display the optimized parameters. To obtain those, we use the `get_weights` method of the layer we're interested in (in this case, the only layer), which returns the weights of the layer as a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_w_np, optimal_b_np = model.layers[0].get_weights()\n",
    "\n",
    "type(optimal_w_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now it's more convenient to have these as floating point numbers instead, so we'll go ahead and convert them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_w = float(optimal_w_np)\n",
    "optimal_b = float(optimal_b_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"w: %.3f\" % optimal_w)\n",
    "print(\"b: %.3f\" % optimal_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these optimized parameters with the ones you guessed before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5  Compare optimal and guessed values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it's also beneficial to compare the guessed parameters with the optimized ones graphically, by showing both of the predicted lines in the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "fig, ax = plt.subplots()\n",
    "plot_data_and_line(w, b, x, y, ax, 'r', 'guess')\n",
    "plot_data_and_line(optimal_w, optimal_b, x, y, ax, 'b', 'optimal')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Bonus: Visualizing the optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clearly understand what's going on when we call the Keras `fit` function, it's helpful to illustrate the optimization trajectory. That is, we would like to plot the level curves of the loss function in the parameter space, together with the values of `w` and `b` at each time step of the iteration.\n",
    "\n",
    "First, we import the [`Callback`](https://github.com/keras-team/keras/blob/master/keras/callbacks.py) class, along with Adam and SGD optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a callback to save the weights at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback to save the weights at each iteration\n",
    "class saveWeightsCallback(Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.w = [float(self.model.layers[0].get_weights()[0])]\n",
    "        self.b = [float(self.model.layers[0].get_weights()[1])]\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.w.append(float(self.model.layers[0].get_weights()[0]))\n",
    "        self.b.append(float(self.model.layers[0].get_weights()[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the model, passing the newly created callback as argument to the `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model to be optimized with SGD\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=1, kernel_initializer='zeros', bias_initializer='zeros'))\n",
    "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01, momentum=0.1))\n",
    "\n",
    "# Train it\n",
    "print('Training...')\n",
    "history = saveWeightsCallback()\n",
    "model.fit(x,y,epochs=100, callbacks=[history], verbose=0, batch_size=32);\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.w, history.b, '-ro');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to compute the MSE in a grid of points, so that we can plot level curves with `matplotlib` `contour` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmin = min(history.w)\n",
    "wmax = max(history.w)\n",
    "bmin = min(history.b)\n",
    "bmax = max(history.b)\n",
    "\n",
    "# Create grid of values\n",
    "n = 400\n",
    "w_range = np.linspace(min(0,wmin),max(2,wmax),n)\n",
    "b_range = np.linspace(min(-1,bmin), max(1,bmax),n)\n",
    "w_grid, b_grid = np.meshgrid(w_range, b_range)\n",
    "\n",
    "# Compute MSE at each one\n",
    "MSE_grid = np.ndarray((n,n))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        w = w_grid[i,j]\n",
    "        b = b_grid[i,j]\n",
    "        y_ = w*x + b\n",
    "        MSE_grid[i,j] = MSE(y_,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to plot. \n",
    "\n",
    "However, before doing that, can you guess how the level curves for this loss should look like? Will they be circles, ellipses, something else? Will they be aligned with the axes? Do we have one or many global optima?\n",
    "\n",
    "What about the optimization trajectory? How should it look like? What do you expect to see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the MSE level curves \n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "p = ax.contour(w_grid, b_grid, MSE_grid, np.linspace(0, 40, 100), cmap='hot')\n",
    "\n",
    "# Plot the optimization trajectory\n",
    "ax.plot(history.w, history.b, '-ro')\n",
    "\n",
    "# Plot the global optimum\n",
    "optimal = np.polyfit(x,y,1)\n",
    "ax.plot(optimal[0], optimal[1], 'bx')\n",
    "\n",
    "# Axis' labels, colorbar\n",
    "fig.colorbar(p, ax=ax, ticks=np.linspace(0,40,9))\n",
    "ax.set_xlabel('w')\n",
    "ax.set_ylabel('b');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different batch sizes, learning rates, number of epochs, or even a different optimizer, like Adam."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
