{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 117, 4)\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "train = np.load('train_data_abs_coord.npy').astype(float)\n",
    "val = np.load('test_data_abs_coord.npy').astype(float)\n",
    "print((train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, LSTM, CuDNNLSTM, RepeatVector\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras import objectives\n",
    "\n",
    "\n",
    "def create_lstm_vae(input_dim, \n",
    "    timesteps, \n",
    "    batch_size, \n",
    "    intermediate_dim, \n",
    "    latent_dim,\n",
    "    epsilon_std=1.):\n",
    "\n",
    "    \"\"\"\n",
    "    Creates an LSTM Variational Autoencoder (VAE). Returns VAE, Encoder, Generator. \n",
    "    # Arguments\n",
    "        input_dim: int.\n",
    "        timesteps: int, input timestep dimension.\n",
    "        batch_size: int.\n",
    "        intermediate_dim: int, output shape of LSTM. \n",
    "        latent_dim: int, latent z-layer shape. \n",
    "        epsilon_std: float, z-layer sigma.\n",
    "    # References\n",
    "        - [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)\n",
    "        - [Generating sentences from a continuous space](https://arxiv.org/abs/1511.06349)\n",
    "    \"\"\"\n",
    "    x = Input(shape=(timesteps, input_dim,))\n",
    "\n",
    "    # LSTM encoding\n",
    "    h = CuDNNLSTM(intermediate_dim)(x)\n",
    "\n",
    "    # VAE Z layer\n",
    "    z_mean = Dense(latent_dim)(h)\n",
    "    z_log_sigma = Dense(latent_dim)(h)\n",
    "    \n",
    "    def sampling(args):\n",
    "        z_mean, z_log_sigma = args\n",
    "        epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
    "                                  mean=0., stddev=epsilon_std)\n",
    "        return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "    # so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])\n",
    "    \n",
    "    # decoded LSTM layer\n",
    "    decoder_h = CuDNNLSTM(intermediate_dim, return_sequences=True)\n",
    "    decoder_mean = LSTM(input_dim, return_sequences=True,activation='linear')\n",
    "\n",
    "    h_decoded = RepeatVector(timesteps)(z)\n",
    "    h_decoded = decoder_h(h_decoded)\n",
    "\n",
    "    # decoded layer\n",
    "    x_decoded_mean = decoder_mean(h_decoded)\n",
    "    \n",
    "    # end-to-end autoencoder\n",
    "    vae = Model(x, x_decoded_mean)\n",
    "\n",
    "    # encoder, from inputs to latent space\n",
    "    encoder = Model(x, z_mean)\n",
    "\n",
    "    # generator, from latent space to reconstructed inputs\n",
    "    decoder_input = Input(shape=(latent_dim,))\n",
    "\n",
    "    _h_decoded = RepeatVector(timesteps)(decoder_input)\n",
    "    _h_decoded = decoder_h(_h_decoded)\n",
    "\n",
    "    _x_decoded_mean = decoder_mean(_h_decoded)\n",
    "    generator = Model(decoder_input, _x_decoded_mean)\n",
    "    \n",
    "    def vae_loss(x, x_decoded_mean):\n",
    "        xent_loss = objectives.mse(x, x_decoded_mean)\n",
    "        kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma))\n",
    "        loss = xent_loss + kl_loss\n",
    "        return loss\n",
    "    opt=Adam(lr=0.0001)\n",
    "    vae.compile(optimizer=opt, loss=vae_loss)\n",
    "    \n",
    "    return vae, encoder, generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/23\n",
      "60000/60000 [==============================] - 58s 961us/step - loss: 3.9897 - val_loss: 4.1704\n",
      "Epoch 2/23\n",
      "60000/60000 [==============================] - 55s 911us/step - loss: 4.0747 - val_loss: 3.8765\n",
      "Epoch 3/23\n",
      "60000/60000 [==============================] - 55s 909us/step - loss: 3.8618 - val_loss: 3.7402\n",
      "Epoch 4/23\n",
      "60000/60000 [==============================] - 55s 911us/step - loss: 3.7359 - val_loss: 3.6132\n",
      "Epoch 5/23\n",
      "60000/60000 [==============================] - 55s 915us/step - loss: 3.5639 - val_loss: 3.4019\n",
      "Epoch 6/23\n",
      "60000/60000 [==============================] - 55s 915us/step - loss: 3.4578 - val_loss: 3.3830\n",
      "Epoch 7/23\n",
      "60000/60000 [==============================] - 55s 917us/step - loss: 3.4707 - val_loss: 3.4195\n",
      "Epoch 8/23\n",
      "60000/60000 [==============================] - 55s 916us/step - loss: 3.4565 - val_loss: 3.3812\n",
      "Epoch 9/23\n",
      "60000/60000 [==============================] - 55s 915us/step - loss: 3.4724 - val_loss: 3.4241\n",
      "Epoch 10/23\n",
      "60000/60000 [==============================] - 55s 914us/step - loss: 3.4623 - val_loss: 3.3851\n",
      "Epoch 11/23\n",
      "60000/60000 [==============================] - 55s 913us/step - loss: 3.4742 - val_loss: 3.3935\n",
      "Epoch 12/23\n",
      "60000/60000 [==============================] - 55s 916us/step - loss: 3.4725 - val_loss: 3.3959\n",
      "Epoch 13/23\n",
      "60000/60000 [==============================] - 55s 917us/step - loss: 3.4614 - val_loss: 3.4175\n",
      "Epoch 14/23\n",
      "60000/60000 [==============================] - 55s 916us/step - loss: 3.4596 - val_loss: 3.3988\n",
      "Epoch 15/23\n",
      "60000/60000 [==============================] - 55s 916us/step - loss: 3.4668 - val_loss: 3.4053\n",
      "Epoch 16/23\n",
      "60000/60000 [==============================] - 55s 915us/step - loss: 3.4668 - val_loss: 3.4008\n",
      "Epoch 17/23\n",
      "60000/60000 [==============================] - 55s 914us/step - loss: 3.4635 - val_loss: 3.4101\n",
      "Epoch 18/23\n",
      "60000/60000 [==============================] - 55s 915us/step - loss: 3.4607 - val_loss: 3.3809\n",
      "Epoch 19/23\n",
      "60000/60000 [==============================] - 55s 910us/step - loss: 3.4547 - val_loss: 3.4132\n",
      "Epoch 20/23\n",
      "60000/60000 [==============================] - 55s 911us/step - loss: 3.4585 - val_loss: 3.4042\n",
      "Epoch 21/23\n",
      "60000/60000 [==============================] - 55s 913us/step - loss: 3.4573 - val_loss: 3.3957\n",
      "Epoch 22/23\n",
      "60000/60000 [==============================] - 55s 914us/step - loss: 3.5016 - val_loss: 3.4387\n",
      "Epoch 23/23\n",
      "60000/60000 [==============================] - 55s 913us/step - loss: 3.5273 - val_loss: 3.4609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b5eabdf358>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard,ModelCheckpoint    \n",
    "from time import time\n",
    "\n",
    "\n",
    "_,timesteps,input_dim=train.shape\n",
    "# Hyper paramters for network\n",
    "intermediate_dim = 512\n",
    "latent_dim = 128\n",
    "batch_size = 500\n",
    "vae, encoder, generator = create_lstm_vae(  input_dim, \n",
    "                                            timesteps, \n",
    "                                            batch_size, \n",
    "                                            intermediate_dim, \n",
    "                                            latent_dim,\n",
    "                                            epsilon_std=1.)\n",
    "# Hyper parmaeters for training\n",
    "batch_size = batch_size\n",
    "epochs = 23\n",
    "time=time()\n",
    "Name=\"tewst\"#f\"lat:{latent_dim}-inter:{intermediate_dim}-time{time}.\"\n",
    "os.getcwd()\n",
    "tensorboard = TensorBoard(log_dir=\"logs/\"+Name)\n",
    "modelcheckpoint = ModelCheckpoint(\"model/\"+Name+\"epo:{epoch:02d}-val_loss{val_loss:.2f}.hdf5\",monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "callbacks =[tensorboard,modelcheckpoint]\n",
    "\n",
    "\n",
    "# Training with abs coord (intermediate_dim = 512) fairly succesfull up to 23 epochs\n",
    "                        #(latent_dim = 128)\n",
    "                        #(batch_size = 500)\n",
    "\n",
    "vae.fit( x = train, y = train, batch_size = batch_size , epochs = epochs, validation_data=(val, val),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.fit( x = train, y = train, batch_size = batch_size , epochs = epochs, validation_data=(val, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import keras.losses\n",
    "# VAE Z layer\n",
    "z_mean = Dense(latent_dim)\n",
    "z_log_sigma = Dense(latent_dim)\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = objectives.mse(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma))\n",
    "    loss = xent_loss + kl_loss\n",
    "    return loss\n",
    "keras.losses.vae_loss = vae_loss\n",
    "#vae=load_model('model/latent_dim128-intermediate_dim512-time1540355769.8443556.weights-23-3.41.hdf5', custom_objects={'vae_loss': vae_loss})\n",
    "predicted=vae.predict(train[0:batch_size],batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "b=89\n",
    "plt.close()\n",
    "predicted_abs=np.cumsum(predicted,axis=0)\n",
    "plt.subplot(211)\n",
    "#plt.plot(np.cumsum(predicted[b,:,0]), np.cumsum(predicted[b,:,1]), 'ro')\n",
    "plt.plot(predicted[b,:,0],predicted[b,:,1], 'ro')\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "plt.subplot(212)\n",
    "#plt.plot(np.cumsum(train[b,:,0]), np.cumsum(train[b,:,1]), 'ro')\n",
    "plt.plot(train[b,:,0], train[b,:,1], 'ro')\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\bjorn\\\\Documents\\\\Repositories\\\\DeepMachineLearning\\\\Project'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "time=time()\n",
    "intermediate_dim = 512\n",
    "latent_dim = 64\n",
    "batch_size = 500\n",
    "Name=f\"latent_dim:{latent_dim}-intermediate_dim:{intermediate_dim}-batch_size:{batch_size}-time:{time}.\"\n",
    "print(Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = objectives.mse(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma))\n",
    "    loss = xent_loss + kl_loss\n",
    "    return loss\n",
    "#vae=load_model('model/latent_dim128-intermediate_dim512-time1540355769.8443556.weights-23-3.41.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
